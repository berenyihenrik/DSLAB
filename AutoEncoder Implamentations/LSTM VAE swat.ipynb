{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0GM4bxG5gHo"
   },
   "source": [
    "# Setup Environment and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10356,
     "status": "ok",
     "timestamp": 1758972140067,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "zhjtQGemJkY-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "from tqdm import trange,tqdm\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNYIVLT3FAuk"
   },
   "source": [
    "## Setup the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3166,
     "status": "ok",
     "timestamp": 1758972149927,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "fn5fwngg0fW8",
    "outputId": "98620fa5-8f8a-47e7-933f-d874020ef425"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beren\\AppData\\Local\\Temp\\ipykernel_22360\\3004897857.py:8: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_train = pd.read_csv(TRAIN_DATASET, header=None)\n",
      "C:\\Users\\beren\\AppData\\Local\\Temp\\ipykernel_22360\\3004897857.py:9: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_test = pd.read_csv(TEST_DATASET, header=None)\n"
     ]
    }
   ],
   "source": [
    "DRIVE = \"drive/MyDrive/Colab Notebooks/ELTE/DSLAB/swat/\"\n",
    "DRIVE = \"swat/\"\n",
    "TRAIN_FILE_NAME = \"SWaT_Dataset_Normal_v0 1.csv\"\n",
    "TRAIN_DATASET = DRIVE + TRAIN_FILE_NAME\n",
    "TEST_FILE_NAME = \"SWaT_Dataset_Attack_v0 1.csv\"\n",
    "TEST_DATASET = DRIVE + TEST_FILE_NAME\n",
    "\n",
    "data_train = pd.read_csv(TRAIN_DATASET, header=None)\n",
    "data_test = pd.read_csv(TEST_DATASET, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3972,
     "status": "ok",
     "timestamp": 1758972158868,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "knT8HtvEyXIq"
   },
   "outputs": [],
   "source": [
    "data_train.replace(\"Normal\", 0, inplace=True)\n",
    "data_test.replace(\"Normal\", 0, inplace=True)\n",
    "data_test.replace(\"Attack\", 1, inplace=True)\n",
    "data_test.replace(\"A ttack\", 1, inplace=True)\n",
    "\n",
    "train = data_train.iloc[:, 1:].copy()\n",
    "train = train.iloc[:, :-1].copy()\n",
    "test = data_test.iloc[:, 1:].copy()\n",
    "test = test.iloc[:, :-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1758972158882,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "eoqn0QaeyZ71"
   },
   "outputs": [],
   "source": [
    "true_anomalies = data_test[52].to_numpy()\n",
    "true_anomalies = np.delete(true_anomalies, 0)\n",
    "true_anomalies = true_anomalies.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1758972158885,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "R4WWu1NFybXr",
    "outputId": "037c1b4d-b264-471f-fb5b-f227256e37f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1758972159030,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "n1sO05uhybq9",
    "outputId": "45764280-a8fa-4c0f-821e-19e292b15df2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIT101</td>\n",
       "      <td>LIT101</td>\n",
       "      <td>MV101</td>\n",
       "      <td>P101</td>\n",
       "      <td>P102</td>\n",
       "      <td>AIT201</td>\n",
       "      <td>AIT202</td>\n",
       "      <td>AIT203</td>\n",
       "      <td>FIT201</td>\n",
       "      <td>MV201</td>\n",
       "      <td>...</td>\n",
       "      <td>FIT504</td>\n",
       "      <td>P501</td>\n",
       "      <td>P502</td>\n",
       "      <td>PIT501</td>\n",
       "      <td>PIT502</td>\n",
       "      <td>PIT503</td>\n",
       "      <td>FIT601</td>\n",
       "      <td>P601</td>\n",
       "      <td>P602</td>\n",
       "      <td>P603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.470294</td>\n",
       "      <td>261.5804</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.19008</td>\n",
       "      <td>306.101</td>\n",
       "      <td>2.471278</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.457163</td>\n",
       "      <td>261.1879</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.19008</td>\n",
       "      <td>306.101</td>\n",
       "      <td>2.468587</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.439548</td>\n",
       "      <td>260.9131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.19008</td>\n",
       "      <td>306.101</td>\n",
       "      <td>2.467305</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.428338</td>\n",
       "      <td>260.285</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>244.3284</td>\n",
       "      <td>8.19008</td>\n",
       "      <td>306.101</td>\n",
       "      <td>2.466536</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.02948</td>\n",
       "      <td>0</td>\n",
       "      <td>4.277749</td>\n",
       "      <td>0.000256304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496796</th>\n",
       "      <td>2.460366</td>\n",
       "      <td>523.043</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.5055</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308619</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8171</td>\n",
       "      <td>1.778105</td>\n",
       "      <td>189.8552</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496797</th>\n",
       "      <td>2.448836</td>\n",
       "      <td>522.9645</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.5055</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308619</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8171</td>\n",
       "      <td>1.778105</td>\n",
       "      <td>189.5027</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496798</th>\n",
       "      <td>2.434744</td>\n",
       "      <td>522.886</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.444879</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308619</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8171</td>\n",
       "      <td>1.778105</td>\n",
       "      <td>189.5027</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496799</th>\n",
       "      <td>2.428338</td>\n",
       "      <td>522.9252</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308619</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8171</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.5027</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496800</th>\n",
       "      <td>2.427057</td>\n",
       "      <td>522.8467</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307786</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8652</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.5988</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496801 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2      3     4     5         6         7         8   \\\n",
       "0         FIT101    LIT101  MV101  P101  P102    AIT201    AIT202    AIT203   \n",
       "1       2.470294  261.5804      2     2     1  244.3284   8.19008   306.101   \n",
       "2       2.457163  261.1879      2     2     1  244.3284   8.19008   306.101   \n",
       "3       2.439548  260.9131      2     2     1  244.3284   8.19008   306.101   \n",
       "4       2.428338   260.285      2     2     1  244.3284   8.19008   306.101   \n",
       "...          ...       ...    ...   ...   ...       ...       ...       ...   \n",
       "496796  2.460366   523.043      2     2     1  262.0161  8.396437  328.5055   \n",
       "496797  2.448836  522.9645      2     2     1  262.0161  8.396437  328.5055   \n",
       "496798  2.434744   522.886      2     2     1  262.0161  8.396437  328.6337   \n",
       "496799  2.428338  522.9252      2     2     1  262.0161  8.396437  328.6337   \n",
       "496800  2.427057  522.8467      2     2     1  262.0161  8.396437  328.6337   \n",
       "\n",
       "              9      10  ...        42    43    44        45        46  \\\n",
       "0         FIT201  MV201  ...    FIT504  P501  P502    PIT501    PIT502   \n",
       "1       2.471278      2  ...         0     1     1  10.02948         0   \n",
       "2       2.468587      2  ...         0     1     1  10.02948         0   \n",
       "3       2.467305      2  ...         0     1     1  10.02948         0   \n",
       "4       2.466536      2  ...         0     1     1  10.02948         0   \n",
       "...          ...    ...  ...       ...   ...   ...       ...       ...   \n",
       "496796  2.442316      2  ...  0.308619     2     1  250.8171  1.778105   \n",
       "496797  2.442316      2  ...  0.308619     2     1  250.8171  1.778105   \n",
       "496798  2.444879      2  ...  0.308619     2     1  250.8171  1.778105   \n",
       "496799  2.445391      2  ...  0.308619     2     1  250.8171  1.649953   \n",
       "496800  2.445391      2  ...  0.307786     2     1  250.8652  1.649953   \n",
       "\n",
       "              47           48    49    50    51  \n",
       "0         PIT503       FIT601  P601  P602  P603  \n",
       "1       4.277749  0.000256304     1     1     1  \n",
       "2       4.277749  0.000256304     1     1     1  \n",
       "3       4.277749  0.000256304     1     1     1  \n",
       "4       4.277749  0.000256304     1     1     1  \n",
       "...          ...          ...   ...   ...   ...  \n",
       "496796  189.8552     0.000128     1     1     1  \n",
       "496797  189.5027     0.000128     1     1     1  \n",
       "496798  189.5027     0.000128     1     1     1  \n",
       "496799  189.5027     0.000128     1     1     1  \n",
       "496800  189.5988     0.000128     1     1     1  \n",
       "\n",
       "[496801 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 126,
     "status": "ok",
     "timestamp": 1758972159157,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "9lJI-vVVydrP",
    "outputId": "2ee1d9bf-c288-4302-8438-52fa3b82f9e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIT101</td>\n",
       "      <td>LIT101</td>\n",
       "      <td>MV101</td>\n",
       "      <td>P101</td>\n",
       "      <td>P102</td>\n",
       "      <td>AIT201</td>\n",
       "      <td>AIT202</td>\n",
       "      <td>AIT203</td>\n",
       "      <td>FIT201</td>\n",
       "      <td>MV201</td>\n",
       "      <td>...</td>\n",
       "      <td>FIT504</td>\n",
       "      <td>P501</td>\n",
       "      <td>P502</td>\n",
       "      <td>PIT501</td>\n",
       "      <td>PIT502</td>\n",
       "      <td>PIT503</td>\n",
       "      <td>FIT601</td>\n",
       "      <td>P601</td>\n",
       "      <td>P602</td>\n",
       "      <td>P603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.427057</td>\n",
       "      <td>522.8467</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3077859</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8652</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.5988</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.446274</td>\n",
       "      <td>522.886</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3077859</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8652</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6789</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.489191</td>\n",
       "      <td>522.8467</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.394514</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3086186</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8812</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6789</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.53435</td>\n",
       "      <td>522.9645</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.394514</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3086186</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.8812</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.6148</td>\n",
       "      <td>0.000128152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449915</th>\n",
       "      <td>2.559972</td>\n",
       "      <td>519.5495</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0979</td>\n",
       "      <td>8.638683</td>\n",
       "      <td>301.9226</td>\n",
       "      <td>2.459488</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306569</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>251.1535</td>\n",
       "      <td>0.865024</td>\n",
       "      <td>189.022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449916</th>\n",
       "      <td>2.549082</td>\n",
       "      <td>520.4131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0979</td>\n",
       "      <td>8.638683</td>\n",
       "      <td>301.9226</td>\n",
       "      <td>2.459488</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306569</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>251.0734</td>\n",
       "      <td>0.865024</td>\n",
       "      <td>188.9259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449917</th>\n",
       "      <td>2.531467</td>\n",
       "      <td>520.6878</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0979</td>\n",
       "      <td>8.638683</td>\n",
       "      <td>301.9226</td>\n",
       "      <td>2.460129</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306569</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>251.0734</td>\n",
       "      <td>0.865024</td>\n",
       "      <td>188.9259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449918</th>\n",
       "      <td>2.521218</td>\n",
       "      <td>520.7271</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0979</td>\n",
       "      <td>8.638683</td>\n",
       "      <td>301.9226</td>\n",
       "      <td>2.460129</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307978</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>251.0734</td>\n",
       "      <td>0.865024</td>\n",
       "      <td>188.9259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449919</th>\n",
       "      <td>2.501681</td>\n",
       "      <td>521.1196</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>168.0979</td>\n",
       "      <td>8.638683</td>\n",
       "      <td>301.9226</td>\n",
       "      <td>2.458206</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308298</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>251.0734</td>\n",
       "      <td>0.865024</td>\n",
       "      <td>188.9259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449920 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2       3     4     5         6         7         8   \\\n",
       "0         FIT101    LIT101   MV101  P101  P102    AIT201    AIT202    AIT203   \n",
       "1       2.427057  522.8467       2     2     1  262.0161  8.396437  328.6337   \n",
       "2       2.446274   522.886       2     2     1  262.0161  8.396437  328.6337   \n",
       "3       2.489191  522.8467       2     2     1  262.0161  8.394514  328.6337   \n",
       "4        2.53435  522.9645       2     2     1  262.0161  8.394514  328.6337   \n",
       "...          ...       ...     ...   ...   ...       ...       ...       ...   \n",
       "449915  2.559972  519.5495       2     2     1  168.0979  8.638683  301.9226   \n",
       "449916  2.549082  520.4131       2     2     1  168.0979  8.638683  301.9226   \n",
       "449917  2.531467  520.6878       2     2     1  168.0979  8.638683  301.9226   \n",
       "449918  2.521218  520.7271       2     2     1  168.0979  8.638683  301.9226   \n",
       "449919  2.501681  521.1196       2     2     1  168.0979  8.638683  301.9226   \n",
       "\n",
       "              9       10  ...         42    43    44        45        46  \\\n",
       "0         FIT201   MV201  ...     FIT504  P501  P502    PIT501    PIT502   \n",
       "1       2.445391       2  ...  0.3077859     2     1  250.8652  1.649953   \n",
       "2       2.445391       2  ...  0.3077859     2     1  250.8652  1.649953   \n",
       "3       2.442316       2  ...  0.3086186     2     1  250.8812  1.649953   \n",
       "4       2.442316       2  ...  0.3086186     2     1  250.8812  1.649953   \n",
       "...          ...     ...  ...        ...   ...   ...       ...       ...   \n",
       "449915  2.459488       2  ...   0.306569     2     1  251.1535  0.865024   \n",
       "449916  2.459488       2  ...   0.306569     2     1  251.0734  0.865024   \n",
       "449917  2.460129       2  ...   0.306569     2     1  251.0734  0.865024   \n",
       "449918  2.460129       2  ...   0.307978     2     1  251.0734  0.865024   \n",
       "449919  2.458206       2  ...   0.308298     2     1  251.0734  0.865024   \n",
       "\n",
       "              47           48    49    50    51  \n",
       "0         PIT503       FIT601  P601  P602  P603  \n",
       "1       189.5988  0.000128152     1     1     1  \n",
       "2       189.6789  0.000128152     1     1     1  \n",
       "3       189.6789  0.000128152     1     1     1  \n",
       "4       189.6148  0.000128152     1     1     1  \n",
       "...          ...          ...   ...   ...   ...  \n",
       "449915   189.022          0.0     1     1     1  \n",
       "449916  188.9259          0.0     1     1     1  \n",
       "449917  188.9259          0.0     1     1     1  \n",
       "449918  188.9259          0.0     1     1     1  \n",
       "449919  188.9259          0.0     1     1     1  \n",
       "\n",
       "[449920 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1El1ROXf7unv"
   },
   "source": [
    "# Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6595,
     "status": "ok",
     "timestamp": 1758972169704,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "7NKbSU7O7xZ9",
    "outputId": "75b3e07e-c6d8-443d-9e6d-6df924d23032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with very low variance: [5, 11, 12, 14, 16, 30, 32, 33, 44, 49, 51]\n",
      "Original number of features: 51\n",
      "Number of features after removing low variance columns: 40\n"
     ]
    }
   ],
   "source": [
    "# remove headers\n",
    "if train.iloc[0].dtype == 'object':\n",
    "    train = train[1:].copy()\n",
    "    test = test[1:].copy()\n",
    "\n",
    "# convert all columns to numeric\n",
    "train = train.apply(pd.to_numeric, errors='coerce')\n",
    "test = test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# interpolate/fill NaNs after conversion if necessary\n",
    "train.interpolate(inplace=True)\n",
    "train.bfill(inplace=True)\n",
    "test.interpolate(inplace=True)\n",
    "test.bfill(inplace=True)\n",
    "\n",
    "# calculate variance, crop columns with variance close to zero.\n",
    "variance_threshold = 1e-6\n",
    "variances = train.var()\n",
    "low_variance_cols = variances[variances < variance_threshold].index\n",
    "\n",
    "print(f\"Columns with very low variance: {list(low_variance_cols)}\")\n",
    "\n",
    "# drop low variance columns\n",
    "train_filtered = train.drop(columns=low_variance_cols)\n",
    "test_filtered = test.drop(columns=low_variance_cols)\n",
    "\n",
    "print(f\"Original number of features: {train.shape[1]}\")\n",
    "print(f\"Number of features after removing low variance columns: {train_filtered.shape[1]}\")\n",
    "\n",
    "# egenerate the tensors and dataloaders with the filtered data\n",
    "train_tensor = train_filtered.values\n",
    "test_tensor = test_filtered.values\n",
    "\n",
    "sequence_length = 30\n",
    "sequences = []\n",
    "for i in range(train_tensor.shape[0] - sequence_length + 1):\n",
    "  sequences.append(train_tensor[i:i + sequence_length])\n",
    "\n",
    "train_data, val_data = train_test_split(sequences, test_size=0.3, random_state=42, shuffle=False) # 70% train, 30% temp\n",
    "\n",
    "test_sequences = []\n",
    "for i in range(test_tensor.shape[0] - sequence_length + 1):\n",
    "  test_sequences.append(test_tensor[i:i + sequence_length])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_sequences, batch_size=batch_size, shuffle=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1758972169717,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "LZRfBsc7P70-",
    "outputId": "a60039c2-6ca0-49c9-b3f2-78178e943f82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_nZLXQN7yKW"
   },
   "source": [
    "# Define the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10IVAB_oBek_"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1758972172547,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "DVML-8z6BZRt"
   },
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, num_layers=1):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)  # h_n: (num_layers, batch, hidden_dim)\n",
    "        h = h_n[-1]  # take the output of the last layer\n",
    "        return self.fc_mean(h), self.fc_logvar(h)\n",
    "\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, sequence_length, num_layers=1):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.latent_to_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Repeat z for each timestep\n",
    "        hidden = self.latent_to_hidden(z).unsqueeze(1).repeat(1, self.sequence_length, 1)\n",
    "        out, _ = self.lstm(hidden)\n",
    "        return self.output_layer(out)\n",
    "\n",
    "\n",
    "class LSTMVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, sequence_length, num_layers=1, device='cpu'):\n",
    "        super(LSTMVAE, self).__init__()\n",
    "        self.encoder = LSTMEncoder(input_dim, hidden_dim, latent_dim, num_layers).to(device)\n",
    "        self.decoder = LSTMDecoder(latent_dim, hidden_dim, input_dim, sequence_length, num_layers).to(device)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1921,
     "status": "ok",
     "timestamp": 1758972178324,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "_-HozbDBQjp_"
   },
   "outputs": [],
   "source": [
    "input_dim = train_filtered.shape[1]\n",
    "hidden_dim = 128\n",
    "latent_dim = 32\n",
    "num_layers = 1\n",
    "\n",
    "model = LSTMVAE(input_dim=input_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                latent_dim=latent_dim,\n",
    "                sequence_length=sequence_length,\n",
    "                num_layers=num_layers,\n",
    "                device=device).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCvCWPSaBjTr"
   },
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1758972179760,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "oC9p-xxjMZa4"
   },
   "outputs": [],
   "source": [
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.mse_loss(x_hat, x, reduction='sum')\n",
    "    KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1758972180780,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "jtWTMS6O0BO0"
   },
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    model_state = {\n",
    "        'input_dim':input_dim,\n",
    "        'latent_dim':latent_dim,\n",
    "        'hidden_dim':hidden_dim,\n",
    "        'state_dict':model.state_dict()\n",
    "    }\n",
    "    torch.save(model_state,'vae_swat.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftEj1OZs78Pk"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG5kpDZaQxEw"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 970981,
     "status": "ok",
     "timestamp": 1758973179812,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "uCnBGx0dQxLi",
    "outputId": "a5ea8784-d39b-45f1-eba3-afe79bee41d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beren\\AppData\\Local\\Temp\\ipykernel_22360\\2253947529.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = torch.tensor(batch, dtype=torch.float32).to(device)\n",
      "C:\\Users\\beren\\AppData\\Local\\Temp\\ipykernel_22360\\2253947529.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = torch.tensor(batch, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001: train loss 478601762.1395, valid loss 24717915.9603\n",
      "Epoch 0002: train loss 25821742.2887, valid loss 13209245.1613\n",
      "Epoch 0003: train loss 10618859.7838, valid loss 8950455.7972\n",
      "Epoch 0004: train loss 9911359.4115, valid loss 9674852.9002\n",
      "Epoch 0005: train loss 8602511.1657, valid loss 4602837.7567\n",
      "Epoch 0006: train loss 3788039.8466, valid loss 4537406.0748\n",
      "Epoch 0007: train loss 8247948.1539, valid loss 6142919.6684\n",
      "Epoch 0008: train loss 20931008.6448, valid loss 20484306.4467\n",
      "Epoch 0009: train loss 23354205.7861, valid loss 16798862.8039\n",
      "Epoch 0010: train loss 13574703.2085, valid loss 9558599.6318\n",
      "Epoch 0011: train loss 10812675.5474, valid loss 8933239.1874\n",
      "Epoch 0012: train loss 11042967.0717, valid loss 10141458.1627\n",
      "Epoch 0013: train loss 10401045.0276, valid loss 8857898.0923\n",
      "Epoch 0014: train loss 10124202.9043, valid loss 8852805.8731\n",
      "Epoch 0015: train loss 10133032.7934, valid loss 8799743.9277\n",
      "Epoch 0016: train loss 9913697.0953, valid loss 8950074.4182\n",
      "Early stopping triggered.\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1)\n",
    "\n",
    "# SPO optimizer - optuna\n",
    "# bayesian hyperparameter tuning\n",
    "# grid search - slow for DL\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, loss_fn, scheduler, num_epochs=10, device='cpu'):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    early_stop_tolerant_count = 0\n",
    "    early_stop_tolerant = 10\n",
    "    best_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            batch = torch.tensor(batch, dtype=torch.float32).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            recon_batch, mean, logvar = model(batch)\n",
    "            loss = loss_fn(recon_batch, batch, mean, logvar)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = torch.tensor(batch, dtype=torch.float32).to(device)\n",
    "                recon_batch, mean, logvar = model(batch)\n",
    "                loss = loss_fn(recon_batch, batch, mean, logvar)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        valid_loss /= len(val_loader)\n",
    "        val_losses.append(valid_loss)\n",
    "\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            early_stop_tolerant_count = 0\n",
    "        else:\n",
    "            early_stop_tolerant_count += 1\n",
    "\n",
    "        print(f\"Epoch {epoch+1:04d}: train loss {train_loss:.4f}, valid loss {valid_loss:.4f}\")\n",
    "\n",
    "        if early_stop_tolerant_count >= early_stop_tolerant:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(\"Finished Training.\")\n",
    "    return train_losses, val_losses\n",
    "\n",
    "train_losses, val_losses = train_model(model, train_loader, val_loader, optimizer, loss_function, scheduler, num_epochs=100, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBvqbBDn7-Lk"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471408,
     "status": "ok",
     "timestamp": 1758973651222,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "Tm2z5saXKo1i",
    "outputId": "cff730f6-cd2d-4221-d64b-e14f5f00f9ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beren\\AppData\\Local\\Temp\\ipykernel_22360\\190499672.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = torch.tensor(batch, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_lstm(model, test_loader, device, percentile_threshold=90):\n",
    "    model.eval()\n",
    "    anomaly_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = torch.tensor(batch, dtype=torch.float32).to(device)\n",
    "\n",
    "            batch_scores = []\n",
    "            for i in range(batch.shape[0]): #Iterate through each sequence in the batch\n",
    "                sequence = batch[i, :, :].unsqueeze(0)  # Select a single sequence\n",
    "                recon_batch, mean, logvar = model(sequence)\n",
    "                loss = loss_function(recon_batch, sequence, mean, logvar)\n",
    "                batch_scores.append(loss.item())\n",
    "            anomaly_scores.extend(batch_scores)  # Append scores for all sequences in the batch\n",
    "\n",
    "\n",
    "    # Calculate the threshold based on the specified percentile\n",
    "    threshold = np.percentile(anomaly_scores, percentile_threshold)\n",
    "\n",
    "    # Identify anomaly indices\n",
    "    anomaly_indices = [i for i, score in enumerate(anomaly_scores) if score > threshold]\n",
    "    return anomaly_indices\n",
    "anomalies = evaluate_lstm(model, test_loader, device, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1758973651244,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "KqE9hY30I1a3",
    "outputId": "545949f2-0f63-4f24-8a30-63f62b6971cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7086035538600542\n"
     ]
    }
   ],
   "source": [
    "def calculate_f1_score(anomaly_indices, true_anomalies):\n",
    "    # Create a binary array representing predicted anomalies\n",
    "    predicted_anomalies = np.zeros_like(true_anomalies)\n",
    "    for index in anomaly_indices:\n",
    "        if index < len(predicted_anomalies):  # Check index bounds\n",
    "          predicted_anomalies[index] = 1\n",
    "\n",
    "    # Calculate the F1 score\n",
    "    f1 = f1_score(true_anomalies, predicted_anomalies)\n",
    "    return f1, predicted_anomalies\n",
    "\n",
    "# Example usage (assuming 'anomalies' and 'true_anomalies' are defined)\n",
    "f1, predicted_anomalies = calculate_f1_score(anomalies, true_anomalies)\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1758973651290,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "2gnQeqVxZ5HY",
    "outputId": "1be807a4-9e51-409c-ca66-fccbbb84913f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96    395298\n",
      "           1       0.78      0.65      0.71     54621\n",
      "\n",
      "    accuracy                           0.94    449919\n",
      "   macro avg       0.87      0.81      0.84    449919\n",
      "weighted avg       0.93      0.94      0.93    449919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_anomalies, predicted_anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1758973651300,
     "user": {
      "displayName": "Henrik Berényi",
      "userId": "03670554175875550861"
     },
     "user_tz": -120
    },
    "id": "f9ymbpd2amAr",
    "outputId": "34c32e6d-6813-4366-80df-85f44a70d7dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[385601   9697]\n",
      " [ 19329  35292]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(true_anomalies, predicted_anomalies))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN7R6pt4VbJZsTEGzTrgrBM",
   "gpuType": "T4",
   "mount_file_id": "1gHANCd3fmZuuaM8XWv5f4xaluG1R24Tk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
